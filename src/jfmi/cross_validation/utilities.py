from collections.abc import Iterable, Iterator

import numpy as np
import pandas as pd
from numpy.typing import NDArray

from jfmi.cross_validation.combinatorial_purged_k_fold import CombinatorialPurgedKFold


def transform_backtest_paths(
    cv: CombinatorialPurgedKFold,
    index: pd.DatetimeIndex = None,
):
    """Transform the backtest_paths dict into a DataFrame.

    Args:
        cv:
            The combinatorial purged cross-validator.
        index:
            A datetime index corresponding to the dataset being split, which if
            supplied, will be used to transform indices into datetimes.

    Returns:
        An aggregated dataframe of backtest paths, their splits, folds, and bounds.
    """
    if not cv.backtest_paths_populated:
        raise RuntimeError(
            "Please populate the backtest paths before calling this function."
        )

    backtest_paths_dfs = []

    for path, data in cv.backtest_paths.items():
        df = pd.DataFrame(data)

        df["path"] = path

        if index is not None:
            df["start_time"] = index[df["start_index"]]
            df["end_time"] = index[df["end_index"]]

        backtest_paths_dfs.append(df)

    return pd.concat(backtest_paths_dfs, ignore_index=True)


def get_cross_validator_bounds(index: pd.DatetimeIndex, split_iterator: Iterable):
    """Get the bounds of each train and test set created by the cross-validator.

    Args:
        index:
            A datetime index corresponding to the dataset being split.
        split_iterator:
            An iterable of (train_indices, test_indices) tuples, typically generated by
            a cross-validator such as TimeSeriesSplit.

    Returns:
        A multi-indexed DataFrame with `split` and `set` index levels, and `start` and
        `end` columns representing the first and last dates of each contiguous segment
        of the training and testing sets for each split.

    Typical usage example:
    >>> index = pd.date_range(start_datetime, end_datetime, freq="D")
    ... cv = TimeSeriesSplit(n_splits=5)
    ... df_bounds = get_cross_validator_bounds(index, cv.split(index))
    """

    def _generate_contiguous_bounds(
        indices: NDArray[np.integer],
    ) -> Iterator[tuple[int, int]]:
        """Yield tuples representing contiguous ranges."""
        # Find the indices where the difference is greater than 1.
        split_points = np.where(np.diff(indices) > 1)[0]

        # If you only were to include the split points, you'd miss the first index, so
        # prepend it to the first position.
        start_indices = np.insert(indices[split_points + 1], 0, indices[0])
        # Similarly, we need to append the final index to the final position.
        end_indices = np.append(indices[split_points], indices[-1])

        return zip(start_indices, end_indices, strict=True)

    bounds = []
    tuples = []

    for fold, (train_index, test_index) in enumerate(split_iterator):
        for start_index, end_index in _generate_contiguous_bounds(train_index):
            tuples.append((fold, "train"))
            bounds.append((index[start_index], index[end_index]))

        for start_i, end_i in _generate_contiguous_bounds(test_index):
            tuples.append((fold, "test"))
            bounds.append((index[start_i], index[end_i]))

    df = pd.DataFrame(
        bounds,
        columns=["start_time", "end_time"],
        index=pd.MultiIndex.from_tuples(tuples, names=["split", "set"]),
    )
    return df
